### 为什么需要多线程

众所周知，CPU、内存、I/O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，  
计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:

- CPU增加了缓存，以均衡与内存的速度差异（导致了可见性问题）
- 操作系统增加了进程、线程的概念，以分时复用CPU，进而均衡CPU与IO设备的速度差异（导致了原子性问题）
- 编译程序优化指令执行次序，使得缓存能够更加充分地利用（导致了有序性问题）
  - 编译器优化重排序，编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
  - 指令级并行重排序，现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。  
    如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
  - 内存系统重排序，由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行

上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。  
对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。  
对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，  
插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，
通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。

### 线程不安全：不是一个非真即假的问题

1. 不可变对象，一定是线程安全的

2. 绝对线程安全，即不管运行时环境如何，调用者都不需要任何额外线程同步的措施。

3. 相对线程安全，相对线程安全需要保证对这个对象单独的操作是线程安全的，在调用的时候不需要做额外的保障措施。但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。

4. 线程兼容，是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时候指的是这一种情况。Java API 中大部分的类都是属于线程兼容的，如与前面的 Vector 和 HashTable 相对应的集合类 ArrayList 和 HashMap 等

### 乐观锁和悲观锁

- 悲观锁：在使用数据时，认为一定会有其他线程来争夺资源，因此修改数据时会先加锁，确保数据不会被别的线程修改。  
  synchronized 和 lock 都是基于悲观锁实现，适合写操作多的场景  
- 乐观锁，则不会加锁，只是会在修改数据之前判断有没有线程已经修改了数据，适合读操作多的场景  

### synchronized原理

加在普通方法上用的是对象锁，加在静态方法上用的是类锁
从字节码角度看 在进入同步代码块之前执行指令monitorenter指令拿到锁 退出时执行monitorexit指令释放锁 中间若有异常 也会释放锁  
synchronized的实现基于管程的思想，管程就是一个软件模块，它封装了一系列保证进程间同步，能够使进程互斥的访问临界资源的操作。  
从jvm源码中看出，ObjectMonitor.hpp,定义了一个监视器

```C
  // initialize the monitor, exception the semaphore, all other fields
  // are simple integers or pointers
  ObjectMonitor() {
    _header       = NULL;
    _count        = 0; // 用于记录该线程获取锁的次数
    _waiters      = 0,
    _recursions   = 0; // 记录锁的重入次数
    _object       = NULL;
    _owner        = NULL; // 指向当前是哪个线程持有这个监视器对象 所以也说明了为什么synchronized(xx)中谁都可以充当锁
    _WaitSet      = NULL; // 等待队列 此队列的线程处于wait
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ; // 阻塞队列 此队列的线程处于block
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
    _previous_owner_tid = 0;
  }
```

### synchronized和Lock区别

1. sync是内置的关键字，Lock是类
2. sync无法判断获取锁的状态，Lock可以判断是否获取到锁
3. sync不需要手动释放锁，Lock必须要手动释放锁
4. sync若线程没有得到锁，则会一直等待下去；而lock可以有选择地等
5. sync可重入锁，不可以中断，非公平锁；lock可重入锁，不可中断，可公平也可非公平
6. sync适合锁少量的同步代码；lock适合锁大量同步代码

### Condition实现精准的通知和唤醒

### 公平锁和非公平锁

公平锁： 指多个线程按照申请资源的顺序来获取锁，先来先服务FIFO，比较公平，但是效率不高，没有考虑到短作业  
非公平锁： 指进程获取锁的顺序不是申请资源的顺序，抢占式，但是在高并发环境下，可能会有进程(线程)一直得不到服务  

恢复挂起的线程到真正的获取到锁是有时间差的，这段时间在CPU看来是有相当一段时间，所以非公平锁能充分利用CPU，提高CPU的利用率，  
此外，线程切换是有开销的，当采用非公平锁时，一个线程的下机，有可能会马上又获得CPU的时间片，所以就减少了线程切换的开销，提高性能。

### 可重入锁(递归锁)

指同一个线程在外层方法获取到锁，再进入该线程的内层方法(同步块，同步方法调用同步块，同步方法)调用会自动获得锁(前提是，锁对象是同一个)，不会因为之前没释放锁而被自己阻塞  
可以一定程度避免死锁  
synchronized隐式递归锁，Lock显示递归锁。  
synchronized实现的原理，当一个线程执行到monitorenter指令时，JVM会检查当前锁对象的_count是不是0，如果是0，则说明当前锁对象没有没其他线程持有，  
JVM就将_owner指向当前线程，并将_count设为1；若再次有线程进入时，在锁对象计数器不为0的情况下，若持锁对象就是当前线程，那么计数器就+1，锁重入次数+1，否则需要等待  
当退出临界区时，计数器依次--，直到计数器的值变为0，则此时线程就释放了锁  

### 死锁

并发环境下，各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程阻塞，不能向前推进的现象

### 线程中断

首先一个线程不应该由其他线程来强行停止，应该时自己主动结束。  
内中断(发生在CPU内部的中断指令)和外中断(CPU外部的中断信号)  
在Java中没有办法立即停止一条线程，但是Java提供了一种停止线程的**协商**机制--中断，中断标识机制  
在Java中，***中断只是一种协商机制***，中断的过程需要程序员自己实现，若要中断一个线程，需要收到调用该线程的interrupt方法，并且该  
方法也只是将线程对象的中断标识位设为true

### LockSupport

之前实现生产者消费者问题，可以使用Object类中的wait和notify方法；也可以使用juc包下的Condition接口中的await和signal方法；  
而现在可以使用LockSupport中的park和unpark方法  

- wait和notify方式前提是必须持有锁，并且wait操作必须在notify之前  

- Condition用法一致

- 基于上述两种方式的限制，就出现了park和unpark(Thread)。  
  LockSupport用于创建锁和其他同步类的基本线程阻塞原语(一旦调用就会将创建锁和进行阻塞两个行为是原子操作)。  
  此类与使用它的每个线程关联一个许可。如果获得许可(permit)，将立即返回对park方法的调用，并在此过程中消耗掉这个许可；  
  否则可能会被阻塞。如果许可尚不可用，调用unpark能让permit可用。(不过与信号量不同，许可证不会累积。最多只能有一个。)
  此种方法是对“忙等”的优化
  
  ```java
  /*
  while (waiters.peek() != current ||
            !locked.compareAndSet(false, true)) {
  
       LockSupport.park(this); // 当前线程不是队首线程或CAS操作不成功 则进入park等待(即进入阻塞) 不会让线程一直在外层的while循环空转
      if (Thread.interrupted()) // ignore interrupts while waiting
        wasInterrupted = true;
    }
  */
  ```

### JMM(Java内存模型)

JMM本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括：

- volatile、synchronized和final关键字

- Happens-Before原则

- 原子性，在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。
  
  - Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。

- 可见性，Java提供了volatile关键字来保证可见性，当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。

- 有序性，可以通过volatile关键字来保证一定的“有序性”。volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成  
  目的是，屏蔽掉各种操作系统和硬件之间内存访问的差异。以实现Java程序在不同环境下都能达到一致的内存访问效果。  
  而**JMM本身是一种抽象的概念，并不真实存在(看不见摸不着)，它仅仅是在描述一种规范，通过规范定义了程序中(尤其是多线程)各个变量的读写访问方式  
  并决定一个线程对共享变量的写入何时以及如何变成对另一个线程可见。围绕多线程的原子性、可见性和有序性展开。**  
  通过JMM来实现线程和主存之间的抽象关系；屏蔽内存访问差异  

- 可见性，线程对内存中的**共享数据**的修改，其他线程能否立即知道该变化，称为可见性。

- 原子性，对数据的访问具有排他性，同一时刻只允许一个线程进入，保证数据的一致性、正确性

- 有序性，指令执行的顺序  

JMM规定了所有的变量都存储在主存。JMM中共享变量在每个线程的工作内存中都有一份共享变量的拷贝副本，对它们的修改都是在自己线程的工作内存中进行的，要避免出现“脏读”。

在JMM中，如果一个**操作的结果**要求对另一个操作可见或者代码重排序，则这两个操作之间必须存在happens-before(先行发生)原则，逻辑上的先后关系(线程同步)。

**先行发生的总原则**：

- 如果一个操作先行发生于另一个操作，那么第一个操作的结果一定要对第二个操作可见，且第一个操作的执行顺序要排在第二个操作之前。
- 若两个操作之间存在先行发生的关系，并不意味着一定要按照先行发生原则指定的顺序来执行。如果重排序之后的执行结果与按照先行发生的顺序执行的**结果一致**，那么这种指令重排序就是**允许的**。

**先行发生的8个原则**：

- 单一线程次序规则，**一个线程内**，按照代码的顺序，写在前面的操作先行发生于写在后面的操作。前一个操作的结果可以被后续操作获取。
- 管程锁定规则，一个解锁的操作（unlock）先行发生于后面对**同一个锁**的上锁（lock）操作。
- volatile变量规则，对一个volatile变量的写操作先行发生于后面的读操作，即写操作对读操作可见。
- 传递规则，若A先于B，B先于C，则一定可以得出A一定先于C
- 线程启动规则，Thread对象的start()方法先行发生于此线程对象的每一个动作（run()方法）
- 线程中断规则，对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；即只有先调用了中断方法才能检测到中断的发生
- 线程终止规则，线程中的所有操作都先行发生于对此线程的终止检测
- 线程终结规则，一个对象的初始化完成操作先行发生于它的finalize()方法的开始

### volatile关键字

特点：可见性和有序性

内存屏障：是一类同步屏障指令，是CPU或编译器对内存随机访问的一个同步点(同步指令)，使得此点之前的所有操作都执行后才可以继续执行后面的指令。在Java中，内存屏障的实现就是在编译源代码时，编译器会生成JVM指令时插入特定的内存屏障指令，通过这些内存屏障指令，volatile变量就实现了JMM中的可见性和有序性，但volatile无法保证原子性(因为没执行到同步点之前的指令并没有加以原子控制，若此时有线程更新了变量，由于可见性就会重新读取值，可能会导致自己的操作结果作废，导致了不可预知的后果)。

写屏障：当JVM执行到Store指令时，就会让操作系统将cache中的数据写回到主存中。

读屏障：CPU在读屏障之后的所有读操作，都在读屏障之后执行，即Load指令之后读到的数据一定时最新的。

1.可以保证线程对被修饰的变量进行读操作时，不会从cache中读取，而是会到主存中立即刷新值然后读取， 既保证了读取到的是最新的值。进行写操作也保证了新值能及时刷新到主存。  
2.禁止了指令重排序优化。 有volatile修饰的变量，赋值后多执行了一个“load addl $0x0, (%esp)”操作， 这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置），
只有一个CPU访问内存时，并不需要内存屏障；（什么是指令重排序：是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理，不存在数据依赖，可以重排序，重排后的语义不能改变原串行语义）

有序性：禁止指令重排序，程序显示告诉JVM哪些地方不要重排序；对于编译器的重排序，JMM会根据重排序的规则，禁止特定类型的编译器重排序；对于处理器的重排序，Java编译器在生成指令序列的特定位置，插入内存屏障指令，来禁止特定类型的处理器排序。

**volatile变量不适合参与到依赖当前值的运算**(因为不能保证原子性)，可以用在**用来保存某个状态的布尔值只是进行单一赋值；开销较低的读写锁；**

### CAS原理

CAS是一种无锁算法，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

从硬件层面看，CAS是一条CPU的一条原子指令(cmpxchg指令)，不会造成数据不一致问题，Unsafe提供的CAS方法底层实现就是CPU的原子指令。执行该指令时，会判断当前系统是否为多核系统，如果是，就给总线加锁，保证只有一个线程会对总线加锁成功，加锁成功之后进行CAS操作，也就是说CAS的原子性是由CPU实现的，比起软件实现，效率肯定很高，不用CPU在内核态和用户态之间切换，排他时间也很短，所以在多线程环境下效率会比较好。

```text
do{

备份旧数据；

基于旧数据构造新数据；

}while(!CAS( 内存地址，备份的旧数据，新数据 ))
```

CPU去更新一个值，发现要更新的值不再是原先的值，操作就失败，因为很显然已经有其他线程修改了这个值。  
就是指当两者进行比较时，如果相等，则证明共享数据没有被修改，替换成新值，然后继续往下运行；  
如果不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作。  
容易看出 CAS 操作是基于共享数据不会被修改的假设，采用了类似于数据库的commit-retry 的模式。当同步冲突出现的机会很少时，这种假设能带来较大的性能提升。  
